{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85dc11cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h1>An Introduction to OpenFace for Head and Face Tracking </h1>\n",
    "\n",
    "\n",
    "<h3> James Trujillo ( james.trujillo@donders.ru.nl )<br>\n",
    "    Wim Pouw ( wim.pouw@donders.ru.nl )<br>\n",
    "    18-11-2021 </h3>\n",
    "    \n",
    "<img src=\"./images/envision_banner.png\"> </center>\n",
    "\n",
    "<h3> Info documents </h3>\n",
    "This Python coding module demonstrates how to use OpenFace, an open-source program that provides face and head tracking of images or videos. We'll go over basic installation, simple commands to run the tracking, and get a first look at the output data.\n",
    "<br><br>\n",
    "\n",
    "* OpenFace: https://github.com/TadasBaltrusaitis/OpenFace\n",
    "* citation: OpenFace 2.0: Facial Behavior Analysis Toolkit Tadas Baltrušaitis, Amir Zadeh, Yao Chong Lim, and Louis-Philippe Morency, IEEE International Conference on Automatic Face and Gesture Recognition, 2018\n",
    "\n",
    "* Visual Studio download (VS required to run OpenFace via command line): https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community&rel=17\n",
    "\n",
    "* A detailed tutorial for using ExploFace: https://github.com/emrecdem/exploface/blob/master/TUTORIALS/tutorial1.ipynb \n",
    "\n",
    "* location code: \n",
    "https://github.com/WimPouw/EnvisionBootcamp2021/tree/main/Python/MediaBodyTracking\n",
    "\n",
    "* packages to download: <i> exploface </i>\n",
    "\n",
    "* citation: \n",
    "Trujillo, J.P. & Pouw, W.(2021-11-18). <i>  An Introduction to OpenFace for Head and Face Tracking</i> \\[day you visited the site]. Retrieved from: https://github.com/WimPouw/EnvisionBootcamp2021/tree/main/Python/MediaBodyTracking \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b1e4ca",
   "metadata": {},
   "source": [
    "<h3> Installing OpenFace </h3>\n",
    "\n",
    "* Download the latest binaries from https://github.com/TadasBaltrusaitis/OpenFace/wiki/Windows-Installation \n",
    "\n",
    "* Unzip the folder into a directory of your choosing -- we recommend unzipping into the FaceTracking_OpenFace directory\n",
    "    \n",
    "* (NOTE: we have provided a 32bit and 64bit folder in the OSF download)\n",
    "\n",
    "* You will also need to download the models that OpenFace uses for Feature Detection\n",
    "  This can be done using powershell (search in your taskbar for powershell, right-click --> Run as administrator\n",
    "  Navigate to the OpenFace directory\n",
    "  Run:  <i> powershell -ExecutionPolicy Bypass -File .\\download_models.psy</i>\n",
    "  You won't see anything directly under your command after running it, but the top of the window should show that your system is downloading it\n",
    "  <img src=\"./images/powershell.png\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e963069b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h3> Running OpenFace </h3>\n",
    "\n",
    "* <b> To run offline </b>, using a GUI, you can navigate to the main folder and run double-click OpenFaceDemo.exe\n",
    "\n",
    "* <b> To run via command line </b>, you need a cmd prompt open to the OpenFace directory\n",
    "For example, I have cmd line running in <i>D:\\data\\MoCap\\OpenFace_2.2.0_win_x64\\OpenFace_2.2.0_win_x64</i>\n",
    "\n",
    "\n",
    "<i>FeatureExtraction.exe</i> is the main function for processing single faces\n",
    "<i>FaceLandmarkVidMulti.exe</i> is used when there are multiple faces\n",
    "\n",
    "For example, to run OF on the sample video provided, we can type the following in cmd:\n",
    "<i>D:\\\n",
    "FeatureExtraction.exe -f \"./samples/2015-10-15-15-14.avi\"</i>\n",
    "OpenFace will update you on the progress\n",
    "<img src=\"./images/OF_running.png\"></center>\n",
    "\n",
    "<br> By default, you get a folder in the OpenFace directory called <i>processed</i> where all the output is stored. However, this means all output .csv files, video files, etc are all thrown in one folder. If you don't want this, you can specify an output directory by adding the following to the FeatureExtraction command:\n",
    "<i>-out_dir \"output_path\"</i> \n",
    "<br>\n",
    "<b> Timing </b>\n",
    "Depending on your machine, OF takes approximately the duration of your video +20% "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a685f3",
   "metadata": {},
   "source": [
    "<h3> OpenFace Output </h3>\n",
    "OpenFace provides several types of output, including a video visualizing the tracking, as well as a .csv containing coordinate data, rotation data, and action units.\n",
    "\n",
    "First, let's take a look at the output video. How does it perform? You should be thinking about the types of questions you want to ask using your data, and take a critical look at whether the tracking is sensitive and accurate enough to serve your purpose. Remember that (some) jitter can be removed with smoothing!\n",
    "\n",
    "Now, let's take a look at the numerical data, and what was actually tracked. <br>\n",
    "<b> Action Units</b><br>\n",
    "OpenFace recognizes a subset of all possible action units. These include:\n",
    "* 1: inner brow raiser\n",
    "* 2: outer brow raiser\n",
    "* 4: brow lowerer\n",
    "* 5: upper lid raiser\n",
    "* 6: cheek raiser\n",
    "* 7: lid tightener\n",
    "* 9: nose wrinkler \n",
    "* 10: upper lip raiser\n",
    "* 12: lip corner puller (smile)\n",
    "* 14: dimpler\n",
    "* 15: lip corner depressor (sad)\n",
    "* 17: chin raiser\n",
    "* 20: lip stretcher\n",
    "* 23: lip tightener\n",
    "* 25: lips part\n",
    "* 26: jaw drop\n",
    "* 28: lip suck – only presence, not intensity\n",
    "* 45: blink\n",
    "<img src=\"./images/AUs.jpg\"></center>\n",
    "<br> \n",
    "OpenFace provides two sets of columns for these AUs. \n",
    "\n",
    "* Presence: given in the AU*_c columns, this just indicates whethere the AU is present in a given frame\n",
    "* Intensity: given in the AU*_r columns, this provides an indication of the intensity of the action unit\n",
    "NOTE: these two values are estimated by two different models, which means sometimes there is no AU detected, but intensity != 0\n",
    "<br>\n",
    "<b> Facial Landmark Coordinates </b><br>\n",
    "We also have facial landmark locations. For each of these 68 landmarks gets at least 4 values: tracking confidence (0-1), tracking success (binary - was anything tracked?), as well as an x and y location, given in pixels\n",
    "<img src=\"./images/landmark_scheme_68.png\"></center>\n",
    "<br>\n",
    "<b>Head Pose </b><br>\n",
    "We also get the relative pose of the head. This is provided in <i>Translation</i>, which gives the location of the head with respect to the camera centre, given in millimiters. We also get <i>Rotation</i> which proves the rotation of the head in radians around the 3 axes<br>\n",
    "* <b>Pitch</b> is the head rotating \"up and down\" (nodding)\n",
    "* <b>Roll</b> is the head tilting side to side (ear to shoulder)\n",
    "* <b>Yaw</b> is the head turning left and right (looking over the shoulder) \n",
    "<br>\n",
    "<b>Eye Gaze</b><br>\n",
    "OpenPose also provides an estimation of the looking direction of the the eyes. This is given in gaze direction, as well as eye landmarks (similar to the facial landmark x,y coordinates).<br>\n",
    "You get both vector coordinates for the eyes (gaze_0_x/y) as well as angular direction (gaze_angle_x/y). <br>\n",
    "Good to know: <br>\n",
    "* all values are given in world coordinates (not relative to head)\n",
    "* angular values will be close to 0 if person is looking straight ahead\n",
    "* angle_x = left to right; angle_y = up and down\n",
    "\n",
    "\n",
    "\n",
    "Rather than write our own scripts to summarize different aspects of the data, we can make use of ExploFace to do much of this\n",
    "(remember to install exploface before running! <i>pip install exploface</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef35f3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3> Importing OpenFace into ELAN Using ExploFace </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed47623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import exploface\n",
    "\n",
    "openface_file = \"./Timeseries_output/sample_vid/2015-10-15-15-14.csv\"\n",
    "\n",
    "openface_features = exploface.get_feature_time_series(openface_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7900dba",
   "metadata": {},
   "source": [
    "This first command just gets the .csv file and loads into a dataframe. This can be a useful starting point if you want to run further analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f9b6cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>face_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>confidence</th>\n",
       "      <th>success</th>\n",
       "      <th>gaze_0_x</th>\n",
       "      <th>gaze_0_y</th>\n",
       "      <th>gaze_0_z</th>\n",
       "      <th>gaze_1_x</th>\n",
       "      <th>gaze_1_y</th>\n",
       "      <th>...</th>\n",
       "      <th>AU12_c</th>\n",
       "      <th>AU14_c</th>\n",
       "      <th>AU15_c</th>\n",
       "      <th>AU17_c</th>\n",
       "      <th>AU20_c</th>\n",
       "      <th>AU23_c</th>\n",
       "      <th>AU25_c</th>\n",
       "      <th>AU26_c</th>\n",
       "      <th>AU28_c</th>\n",
       "      <th>AU45_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.041376</td>\n",
       "      <td>0.020733</td>\n",
       "      <td>-0.998928</td>\n",
       "      <td>-0.096608</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.071931</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>-0.997406</td>\n",
       "      <td>-0.085965</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.074580</td>\n",
       "      <td>-0.003001</td>\n",
       "      <td>-0.997211</td>\n",
       "      <td>-0.097205</td>\n",
       "      <td>-0.005973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.079149</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>-0.996860</td>\n",
       "      <td>-0.108939</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.072152</td>\n",
       "      <td>-0.004155</td>\n",
       "      <td>-0.997385</td>\n",
       "      <td>-0.110762</td>\n",
       "      <td>-0.004892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame  face_id  timestamp  confidence  success  gaze_0_x  gaze_0_y  \\\n",
       "0      1        0      0.000        0.98        1 -0.041376  0.020733   \n",
       "1      2        0      0.033        0.98        1 -0.071931  0.002496   \n",
       "2      3        0      0.067        0.98        1 -0.074580 -0.003001   \n",
       "3      4        0      0.100        0.98        1 -0.079149  0.002348   \n",
       "4      5        0      0.133        0.98        1 -0.072152 -0.004155   \n",
       "\n",
       "   gaze_0_z  gaze_1_x  gaze_1_y  ...  AU12_c  AU14_c  AU15_c  AU17_c  AU20_c  \\\n",
       "0 -0.998928 -0.096608  0.003713  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "1 -0.997406 -0.085965  0.002864  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "2 -0.997211 -0.097205 -0.005973  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "3 -0.996860 -0.108939 -0.002806  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "4 -0.997385 -0.110762 -0.004892  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   AU23_c  AU25_c  AU26_c  AU28_c  AU45_c  \n",
       "0     0.0     0.0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openface_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017508b",
   "metadata": {},
   "source": [
    "Exploface can do a bit more than this though. A useful feature here is to get some summary statistics of what's happening in your video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18bddd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr_detections</th>\n",
       "      <th>average_length_detection</th>\n",
       "      <th>std_average_length_detection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AU01</th>\n",
       "      <td>4</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.777062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU02</th>\n",
       "      <td>8</td>\n",
       "      <td>0.636250</td>\n",
       "      <td>0.660950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU04</th>\n",
       "      <td>22</td>\n",
       "      <td>0.467727</td>\n",
       "      <td>0.456038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU05</th>\n",
       "      <td>10</td>\n",
       "      <td>0.534000</td>\n",
       "      <td>0.312417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU07</th>\n",
       "      <td>3</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.265016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU10</th>\n",
       "      <td>2</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.848528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU15</th>\n",
       "      <td>2</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU17</th>\n",
       "      <td>8</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.190619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU20</th>\n",
       "      <td>2</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.643467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU23</th>\n",
       "      <td>2</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.205061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU26</th>\n",
       "      <td>1</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU45</th>\n",
       "      <td>10</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.598684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nr_detections  average_length_detection  std_average_length_detection\n",
       "AU01              4                  0.947500                      0.777062\n",
       "AU02              8                  0.636250                      0.660950\n",
       "AU04             22                  0.467727                      0.456038\n",
       "AU05             10                  0.534000                      0.312417\n",
       "AU07              3                  0.436667                      0.265016\n",
       "AU10              2                  0.930000                      0.848528\n",
       "AU15              2                  0.550000                      0.070711\n",
       "AU17              8                  0.247500                      0.190619\n",
       "AU20              2                  0.615000                      0.643467\n",
       "AU23              2                  0.315000                      0.205061\n",
       "AU25              1                  0.130000                           NaN\n",
       "AU26              1                  1.440000                           NaN\n",
       "AU45             10                  0.670000                      0.598684"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df = exploface.get_statistics(openface_file)\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e911049",
   "metadata": {},
   "source": [
    "Here we see the Action Unit detections, along with how many there were of each one, and their durations.\n",
    "<br>\n",
    "One of the nicer features here is that we can also convert these .csv data into a .eaf file for use in ELAN. We could then import these annotations into ELAN for further checking/cleaning, or for further analysis in ELAN itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd59383",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_timestamp = exploface.write_elan_file(feature_detections,\n",
    "                                                  video_path=video_file,\n",
    "                                                  output_path=\"sample_vid.eaf\",\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23099ffa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h3>Potential Applications</h3>\n",
    "\n",
    "* Speech-(head)gesture coupling\n",
    "* Automatic gaze detection (who's looking at whom when?)\n",
    "* Others?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8e0e2",
   "metadata": {},
   "source": [
    "<h3> Notes on Reliability </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0695e81a",
   "metadata": {},
   "source": [
    "OpenFace provides some very useful output, and tracking quality seems to be good. However, note that you shouldn't take the output as true until you check it. <br>\n",
    "In particular, many studies use the AU output without any (or very little) quality control. However, a corpus project looking at facial signals in conversation (see Nota et al., 2021; https://doi.org/10.3390/brainsci11081017 ) attempted to use OpenFace, but went with manual coding for most features instead, as AU detection is far from 100% accurate. It can be an interesting starting point to explore data, but the explicit detections absolutely <i>must</i> be checked and cleaned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
